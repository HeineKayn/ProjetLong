{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import projetLib as proj\n",
    "import torch \n",
    "from math import sqrt,ceil\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "resize = (224,224)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "modelsaveFolder = \"./modelSave/\"\n",
    "folder_list = os.listdir(modelsaveFolder) \n",
    "\n",
    "def transformImg(img,resize,doRGB,doCrop):\n",
    "    if doCrop : res = proj.image.Crop_img(resize,doRGB)(img)\n",
    "    else : res = proj.image.Resize_img(resize,doRGB)(img)\n",
    "    return res\n",
    "    \n",
    "def extract_img(filepath):\n",
    "    with open(filepath, 'rb') as img_set:\n",
    "        img_arr = list(img_set.read())\n",
    "        sq   = ceil(sqrt(len(img_arr)))\n",
    "        rest = (sq*sq)-len(img_arr)\n",
    "        img_arr += [0]*rest\n",
    "        img_arr = np.array(img_arr)\n",
    "        img_arr = img_arr.astype('float32')\n",
    "        img_arr = np.reshape(img_arr, (sq,sq))\n",
    "        img_arr = Image.fromarray(img_arr.astype('uint8'), 'L')\n",
    "        return img_arr\n",
    "\n",
    "def predict(malwares,model_type,model_save,resize,doRGB,doCrop):\n",
    "    modelpath = modelsaveFolder + model_save + \"/\"\n",
    "    modelpath += os.listdir(modelpath)[-1]\n",
    "\n",
    "    inputchannels = 1\n",
    "    if doRGB: inputchannels = 3\n",
    "    resize = int(resize)\n",
    "\n",
    "    model = None\n",
    "    if model_type == \"Basic\" : model = proj.model.Basic(inputchannels)\n",
    "    elif model_type == \"Resnet50\" : model = proj.model.getCNNresnet(50,inputchannels)\n",
    "    elif model_type == \"Resnet101\" : model = proj.model.getCNNresnet(101,inputchannels)\n",
    "    elif model_type == \"Resnet152\" : model = proj.model.getCNNresnet(152,inputchannels)\n",
    "    elif model_type == \"VGG\" : model = proj.model.VGG16(inputchannels)\n",
    "    model.load_state_dict(torch.load(modelpath,map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    images = []\n",
    "    tensors = []\n",
    "    for file in malwares:\n",
    "        img = extract_img(file.name)\n",
    "        img = transformImg(img,(resize,resize),doRGB,doCrop)\n",
    "        images.append(img)\n",
    "        tensors.append(transforms.ToTensor()(img))\n",
    "    tensors = torch.stack(tensors)\n",
    "\n",
    "    y = model(tensors)\n",
    "    dic = {}\n",
    "    for i,malware in enumerate(malwares) :\n",
    "        malname = malware.name\n",
    "        if \"\\\\\" in malname : malname = malname.split(\"\\\\\")[-1]\n",
    "        if \"/\" in malname : malname = malname.split(\"/\")[-1]\n",
    "        dic[malname] = y[i].item()\n",
    "    return images,dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 3.0.22, however version 3.14.0 is available, please upgrade.\n",
      "--------\n",
      "Running on local URL:  http://127.0.0.1:7866/\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "demo = gr.Interface(\n",
    "    predict, \n",
    "\n",
    "    [gr.File(file_count=\"multiple\",label=\"Files to analyse\"),\n",
    "     gr.Dropdown([\"Resnet50\",\"Resnet101\",\"Resnet152\",\"VGG\",\"Basic\"],label=\"Model Types\"),\n",
    "     gr.Dropdown(folder_list,label=\"Model Saved\",value=\"resnet50_classic\"),\n",
    "     gr.Number(value=\"224\",label=\"Resize value\"),\n",
    "     gr.Checkbox(label=\"RGB Image\"),\n",
    "     gr.Checkbox(label=\"Crop\",value=True)], \n",
    "\n",
    "    [gr.Gallery(label=\"Malwares en Image\"),\n",
    "     gr.Label(label=\"RÃ©sultat : Malware = 1, Goodware = 0\")]\n",
    "    # examples=[[[os.path.join(os.path.dirname(__file__),\"files/titanic.csv\"), \n",
    "    # os.path.join(os.path.dirname(__file__),\"files/titanic.csv\"), \n",
    "    # os.path.join(os.path.dirname(__file__),\"files/titanic.csv\")]]], \n",
    "    # cache_examples=True\n",
    "    )\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d27e3483a68ae9ee9392c1ae8c113dfd1d356d2ea26a62edcaca8c39a69f0c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
